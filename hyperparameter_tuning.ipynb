{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning using HyperDrive\n",
    "\n",
    "TODO: Import Dependencies. In the cell below, import all the dependencies that you will need to complete the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598531914256
    }
   },
   "outputs": [],
   "source": [
    "from azureml.core import Workspace, Experiment,ScriptRunConfig\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.exceptions import ComputeTargetException\n",
    "from azureml.widgets import RunDetails\n",
    "from azureml.train.sklearn import SKLearn\n",
    "from azureml.train.hyperdrive.run import PrimaryMetricGoal\n",
    "from azureml.train.hyperdrive.policy import BanditPolicy\n",
    "from azureml.train.hyperdrive.sampling import RandomParameterSampling\n",
    "from azureml.train.hyperdrive.runconfig import HyperDriveConfig\n",
    "from azureml.train.hyperdrive.parameter_expressions import uniform,normal,choice\n",
    "from azureml.core.model import InferenceConfig, Model\n",
    "from azureml.core.webservice import AciWebservice, Webservice\n",
    "from azureml.core.environment import Environment\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.data.dataset_factory import TabularDatasetFactory\n",
    "from azureml.core.resource_configuration import ResourceConfiguration\n",
    "import os\n",
    "import joblib\n",
    "import requests\n",
    "import json\n",
    "import sklearn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598531917374
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "ws = Workspace.from_config()\n",
    "\n",
    "experiment_name = 'capstone_project_hyperdrive'\n",
    "\n",
    "experiment=Experiment(ws, experiment_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_cluster_name = \"cpu-cluster\"\n",
    "\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace=ws, name=cpu_cluster_name)\n",
    "    print(\"Found existing cpu-cluster\")\n",
    "except ComputeTargetException:\n",
    "    print(\"Creating new cpu-cluster\")\n",
    "    \n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size=\"STANDARD_D2_V2\",\n",
    "                                                           min_nodes=0,\n",
    "                                                           max_nodes=4)\n",
    "    compute_target = ComputeTarget.create(ws, cpu_cluster_name, compute_config)\n",
    "    \n",
    "compute_target.wait_for_completion(show_output=True)"
   ]
  },
  {
   "source": [
    "## Prepare Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_dataset = TabularDatasetFactory.from_delimited_files(\"https://www.openml.org/data/get_csv/16826755/phpMYEkMl\")\n",
    "ds = remote_dataset.to_pandas_dataframe()\n",
    "\n",
    "if \"data\" not in os.listdir():\n",
    "    os.mkdir(\"./data\")\n",
    "\n",
    "if not os.path.isfile(\"data/titanic.csv\"):\n",
    "    ds.to_csv('data/titanic.csv',index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1598531923519
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Hyperdrive Configuration\n",
    "\n",
    "In this expiremnt we are using HyperDrive which helping us to cover a range of hyperparameters to find the best combination of parameteres to acheive the goal which in our case is Maximizing the Accuracy\n",
    "\n",
    "to detirmine the hyperparametrs what we need to pass to the model and the range of values to cover we are using RandomParameterSampling, which takes the max number of iteration(--max_iter) as a chice of enumeration and the Regularization Strength (--c) as a value between .1 and 1\n",
    "\n",
    "Another argument that we pass to the hyperdriveconfig is the stopping policy, we are using BanditPolicy, in our case each run which is less than 95% of the best performing run will be terminted, this will eliminate runs that get rsults we don't need.\n",
    "\n",
    "There is the main argument which is the estimator which is your algorithm that you will apply, we are using SKLearn, this estimator takes the train.py which is the script file that contains your custome code.\n",
    "\n",
    "The custome code in the train.py using the sklearn LogisticRegression and a method for cleaning the the data, splitting the data to training and testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598544893076
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Create an early termination policy. This is not required if you are using Bayesian sampling.\n",
    "early_termination_policy = BanditPolicy(slack_factor = 0.05, evaluation_interval=3)  \n",
    "\n",
    "#TODO: Create the different params that you will be using during training\n",
    "param_sampling = RandomParameterSampling({\n",
    "        \"--max_iter\": choice(50, 75),\n",
    "        \"--C\": uniform(.4, .6)\n",
    "       \n",
    "    })\n",
    "\n",
    "#TODO: Create your estimator and hyperdrive config\n",
    "estimator = SKLearn(source_directory= './',entry_script='train.py',\n",
    "compute_target = compute_target)\n",
    "\n",
    "hyperdrive_run_config = HyperDriveConfig(estimator = estimator,\n",
    "                                hyperparameter_sampling=param_sampling,\n",
    "                                policy=early_termination_policy,\n",
    "                                primary_metric_name='Accuracy',\n",
    "                                primary_metric_goal=PrimaryMetricGoal.MAXIMIZE,\n",
    "                                max_total_runs=12,\n",
    "                                max_concurrent_runs = 4     \n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598544897941
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#TODO: Submit your experiment\n",
    "hyperdrive_run = experiment.submit(hyperdrive_run_config,show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598546648408
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "RunDetails(hyperdrive_run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598546650307
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "hyperdrive_best_run = hyperdrive_run.get_best_run_by_primary_metric()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperdrive_best_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperdrive_best_run.download_file('outputs/model.pkl', output_file_path='./outputs/model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model.register(workspace=ws,\n",
    "                       model_name='capstone_hyperdrive_best_model',          \n",
    "                       model_path='./outputs/model.pkl', \n",
    "                       model_framework=Model.Framework.SCIKITLEARN,\n",
    "                       model_framework_version=sklearn.__version__)"
   ]
  },
  {
   "source": [
    "## Web Service Deployment"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment_config = AciWebservice.deploy_configuration(cpu_cores = 1,\n",
    "                                                       memory_gb = 1,\n",
    "                                                       auth_enabled=True,\n",
    "                                                       enable_app_insights=True)\n",
    "\n",
    "service_name = 'hyperdrivewebservice'\n",
    "service = Model.deploy(ws, service_name, [model],deployment_config=deployment_config)\n",
    "service.wait_for_deployment(True)"
   ]
  },
  {
   "source": [
    "### Test the deployed service"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "  \"data\": [\n",
    "    {\n",
    "                  \"pclass\": 1,\n",
    "                  \"sex\": 1,\n",
    "                  \"age\": 20,\n",
    "                  \"sibsp\": 1,\n",
    "                  \"parch\": 1,\n",
    "                  \"embarked\": 2\n",
    "    }\n",
    "  ],\n",
    "  \"method\": \"predict\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = json.dumps(data)\n",
    "\n",
    "primaryKey, secondaryKey = service.get_keys()\n",
    "\n",
    "scoring_uri = service.scoring_uri\n",
    "\n",
    "# Set the content type\n",
    "headers = {'Content-Type': 'application/json'}\n",
    "# If authentication is enabled, set the authorization header\n",
    "headers['Authorization'] = f'Bearer {primaryKey}'\n",
    "\n",
    "# Make the request and display the response\n",
    "resp = requests.post(scoring_uri, input_data,headers=headers)\n",
    "\n",
    "print(resp.json())"
   ]
  },
  {
   "source": [
    "## Clear Resources"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the web service\n",
    "service.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete Compute Resources\n",
    "\n",
    "try:\n",
    "    compute_target.delete()\n",
    "except ComputeTargetException:\n",
    "    print(\"cpu-cluster Not Found\")"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}